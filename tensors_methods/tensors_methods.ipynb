{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Criacao e inicializacao de Tensores\n",
    "\n",
    "As operacoes de criacao de tensores no Pytorch sao ferramentas fundamentais, pois sao extremamente utilizadas em Machine Learning, Deep Learning\n",
    "Data Science e em muitas outras √°reas. Nestas √°reas, existe uma grande necessidade de se trabalhar e manipular tensores e abaixo,\n",
    "vamos ilustrar os m√©todos mais utilizados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  **torch.zeros()**: Respons√°vel por criar tensores 'n' dimensional preencchido com zeros, parecido com outros geradores como Numpy no Matlab e ou\n",
    "outras linguagens\n",
    "\n",
    "- **Caso de uso**: Este m√©todo √© muito √∫til quando √© necess√°rio um tensor base para acumular valores, como em somas em um loop\n",
    "ou por exemplo √© extremamente utilizado ao se trabalhar com Backpropagation em redes MLP, para acumular valores ou para inicializar os pesos\n",
    "de uma rede neural, embora seja uma partica menos utilizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem diversas maneiras de se utilizar o `torch.zeros`, para que o m√©todo seja funcional devemos informar para ele pelo menos **1 valor** ou tamb√©m podemos dizer que √© necess√°rio passar ao menos um tensor de ordem 1, pois neste caso se este valor √∫nico for informado ele ir√° retornar um **vetor** ou **tensor** de ordem 1 com a quantidade de zeros preenchida correspondente a quantidade que foi informada no m√©todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0.])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vector = torch.zeros(4)\n",
    "\n",
    "print(vector)\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â poss√≠vel tamb√©m criar tensores de ordem maior por exemplos tensores de ordem 2 e ordem 3 veja:\n",
    "\n",
    "- Vamos inicialmente criar um tensor de ordem 2, para isso veja que iremos informar que queremos 2 linhas e 3 colunas. Logo, o m√©todo torch.zeros(2,3) ir√° retornar uma **matriz** (tensor ordem 2), contendo 2 linhas e 3 colunas. Portanto, √© s√≥ informar a quantidade de elementos que se quer pela quantidade de dimensoes que se quer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.uint32)\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "matrice = torch.zeros(2,3, dtype=torch.uint32)\n",
    "print(matrice)\n",
    "print(matrice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al√©m disso, podemos tamb√©m ter de maneira an√°loga ao feito para o tensor de ordem 2, √© poss√≠vel fazer para o tensor de ordem 3 e a √∫nica modificacao que √© necess√°ria de ser feita √© adicionar uma dimensao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros(2,2,3)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  **torch.ones()**: Respons√°vel por criar um tensor 'n' dimensional preenchido com n√∫meros **1**\n",
    "\n",
    "- **Caso de uso**:  Muito utilizado para criar \"mascaras\", normalmente utilizado no contexto de redes neurais ao se trabalhar com **dropout** com objetivo de evitar ou **diminuir o overfit do modelo**. Mas como assim? o procedimento √© simples como o m√©todo `torch.ones()` nos retorna vetores preenchidos com valores 1, entre estes valores 1 se adicionam valores zero e posteriormente se multiplica pelos valores da entrada da rede neural e ai entao tem-se uma esp√©cie de m√°scara pois qualquer valor multiplicado por zero, sera 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "ord1_tensor = torch.ones(4)\n",
    "print(ord1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ord2_tensor = torch.ones(3,5)\n",
    "print(ord2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "ord3_tensor = torch.ones(3,3,3)\n",
    "print(ord3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo, podemos notar que por mais que estejamos trabalhando com tensores de ordem 0,1,2,3 desde o √≠nicio do estudo de tensores isso nao significa que o m√≥dulo tensor seja limitado a isso. Como ja mencionado durante algumas observacoes e explanacoes, a inicializacao dos tensores pode ser de ordem o at√© ordem n, onde basta adaptar o n√∫mero de dimensoes conforme for necess√°rio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  **torch.rand()**: Cria um tensor com valores alet√≥rios com valores uniformemente distribu√≠dos ou em outras palavras cria ou inicializa um tensor com valores aleat√≥rios seguindo uma distribuicao uniforme\n",
    "- **Caso de uso**: Este m√©todo √© muito utilizado para inicializar os pesos de uma rede neural por exemplo, j√° que normalmente os pesos de uma rede neural sao inicializados com valores aleat√≥rios que posteriormente serao optimizados atrav√©s de alguma t√©cnica de otimizacao como Stocastic Gradient Descent por exemplo. gera valores entre 0 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4887, 0.7744, 0.1333, 0.4912])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(4)\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2579, 0.8253, 0.2264],\n",
      "        [0.3322, 0.0997, 0.7361]])\n"
     ]
    }
   ],
   "source": [
    "rand_tensor1 = torch.rand(2,3)\n",
    "print(rand_tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8243, 0.5449, 0.3278, 0.4985, 0.2112, 0.6157],\n",
      "         [0.0431, 0.5848, 0.0809, 0.1324, 0.6064, 0.2210],\n",
      "         [0.2432, 0.0865, 0.9929, 0.1290, 0.7732, 0.8747]],\n",
      "\n",
      "        [[0.5709, 0.8903, 0.0398, 0.6204, 0.4639, 0.6038],\n",
      "         [0.2114, 0.3910, 0.7623, 0.7430, 0.4407, 0.9496],\n",
      "         [0.4874, 0.6306, 0.2957, 0.8788, 0.6004, 0.7478]]])\n"
     ]
    }
   ],
   "source": [
    "rand_tensor2 = torch.rand(2,3,6)\n",
    "print(rand_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  **torch.randn()**: Este m√©todo √© muito parecido com o torch.rand, por√©m diferentemente ele cria um tensor com valores aleat√≥rios por√©m seguindo uma distribuicao normal, ou tamb√©m muito conhecida como distribuicao gaussiana\n",
    "\n",
    "- **Caso de uso**: E de maneira an√°loga um dos principais caso de uso deste m√©todo e para realizar a inicializacao de pesos de uma rede neural, por√©m este m√©todo tem uma particularidade ele gera valores randomicos com valores entre -1 e 1. (Normal padronizada)  $(\\alpha = 0 , \\theta = 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.4450,  0.1846,  1.5569, -0.8070,  0.8241, -0.8518, -2.6100, -1.0074,\n",
       "        -1.4556, -0.9220])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_tensor = torch.randn(10)\n",
    "gaussian_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6851,  1.7652,  0.1203,  1.9294,  0.9716,  0.4198],\n",
       "        [ 0.4864, -1.0118, -0.1279,  0.1566, -1.4981,  0.5170],\n",
       "        [-0.4545,  1.3726,  0.7099,  0.1283,  1.2079,  0.1762]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_tensor2d = torch.randn(3,6)\n",
    "gaussian_tensor2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0791,  1.9714,  1.5102,  1.2269,  1.0618, -1.6533],\n",
       "         [-1.7467, -0.4388, -0.9460, -2.9648, -0.0447,  0.7426],\n",
       "         [-0.0795, -0.5235,  0.2265,  1.3435, -0.8059, -0.8603]],\n",
       "\n",
       "        [[-0.2372, -0.1399, -2.5591,  0.4283,  2.1688, -0.1868],\n",
       "         [ 0.1828,  0.3666, -2.7581, -0.6882,  1.4558,  1.3762],\n",
       "         [-1.1815, -0.0949,  0.4675, -0.2590, -0.5231, -0.8510]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_tensor3d = torch.randn(2,3,6)\n",
    "gaussian_tensor3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  **torch.arange()**: Este m√©todo cria um tensor com uma sequ√™ncia de valores em um intrevalo espec√≠fico informado como argumento. parecido com as generators functions do Python `range()`\n",
    "\n",
    "- **Caso de uso**: √â bastante utilizado quando se precisa de uma sequ√™ncia n√∫merica cont√≠nua. Um ponto importante a ser mencionado √© que o m√©todo `arange()` s√≥ cria tensores de ordem 1 (vetores), nao sendo poss√≠vel criar tensores de ordem superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = torch.arange(10)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_matrice = torch.arange(2,3,2)\n",
    "numb_matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **torch.full()**: Cria um tensor preenchido com valor especificado como argumento.\n",
    "\n",
    "- **Caso de uso**: Este m√©todo √© muito utilizado quando √© necess√°rio um tensor que cont√©m um valor constante em todas as suas entradas. Isso pode ser √∫til em v√°rias situacoes, como inicializacao de um tensor com um valor de bias por exemplo no contexto de redes neurais. Um coisa importante a ser mencionado √© que o m√©todo `torch.full()` funciona um pouco diferente da seguinte maneira: √© necess√°rio informarmos uma `tupla()` contendo as dimensoes do tensor e tamb√©m o valor que ser√° preenchido veja abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_d = torch.full((10,),0.5)\n",
    "one_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000],\n",
       "        [2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000],\n",
       "        [2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_d = torch.full((3,6),2.5)\n",
    "two_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9800, 0.9800, 0.9800, 0.9800],\n",
       "         [0.9800, 0.9800, 0.9800, 0.9800],\n",
       "         [0.9800, 0.9800, 0.9800, 0.9800]],\n",
       "\n",
       "        [[0.9800, 0.9800, 0.9800, 0.9800],\n",
       "         [0.9800, 0.9800, 0.9800, 0.9800],\n",
       "         [0.9800, 0.9800, 0.9800, 0.9800]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_d = torch.full((2,3,4),0.98)\n",
    "tree_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **torch.from_numpy()**: Este m√©todo √© muito intuitivo pois ele faz literalmente o que seu nome exprime ou seja, este m√©todo cria ou permite inicializar um tensor a partir de um **array Numpy**\n",
    "e como exibido abaixo √© poss√≠vel criar o tensor, atrav√©s do numpy diretamente sem precisar de utilizar o m√©todo `from_numpy()` devido a compatibilidade do torch com o numpy e portanto, pode-se criar diretamente o tensor utilizando o m√≥dulo `torch.tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "\n",
    "np_tensor = torch.from_numpy(x)\n",
    "np_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante a explanacao mostrando os conceitos de inicializacao de tensores, foi poss√≠vel aprender os seguintes m√©todos:\n",
    "1. **torch.zeros()**\n",
    "2. **torch.ones()**\n",
    "3. **torch.rand()**\n",
    "4. **torch.randn()**\n",
    "5. **torch.arange()**\n",
    "6. **torch.full()**\n",
    "7. **torch.from_numpy()**\n",
    "\n",
    "E sendo assim, uma observacao interessante a se fazer e que nao foi explanada durante este notebook √© que todos m√©todos citados acima, cada um deles suportam o argumento: `dtype=torch.<type>`. Entretanto, mesmo que eles suportem o argumento dtype, isso nao quer dizer que todos aceitam os mesmos dytpes, pois existem algumas consideracoes a se fazer.\n",
    "\n",
    "- **Tipos de dados suportados pelo dtype**\n",
    "    - **torch.int8** , **torch.int16** , **torch.int32** , **torch.int64**\n",
    "    - **torch.uint8** , **torch.uint16** , **torch.uint32** , **torch.uint64**\n",
    "    - **torch.float16** , **torch.float32** , **torch.float64**\n",
    "    \n",
    "**OBS**: Entretanto, como observacao o m√©todo **torch.from_numpy()** nao aceita nenhum `dtype` e m√©todos como **torch.rand()** nao aceita nenhuma estrutura de dados **float**, justamente por sua caracteristica de gerar n√∫meros aleat√≥rios entre 0 e 1, a mesma coisa acontece para o **torch.randn()** pois gera n√∫meros entre -1 e 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
