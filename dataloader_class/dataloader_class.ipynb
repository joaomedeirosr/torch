{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A classe Dataloader do PyTorch\n",
    "\n",
    "A classe Dataloader do PyTorch é uma classe muito importante que permite carregar dados em lotes ou seja ela é usada para alimentar os dados que foi representado no`Dataclass` e carerga estes dados no modelo da Rede Neural, isso a torna muito útil para o contexto de Deep Learning. Vamos explorar as mínucias para entender como ela funciona e como podemos utiliza-la para otimizar o processo de treinamento de nossos modelos.\n",
    "\n",
    "##### Importando a classe Dataloader\n",
    "Para importar a classe Dataloader, podemos usar o seguinte comando:\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader\n",
    "```\n",
    "##### Usando a classe Dataloader\n",
    "\n",
    "Para criar um carregador de dados(DataLoader), a primeira coisa que devemos fazer é criar um objeto ou uma instância da classe `DataLoader` e passar alguns argumentos existentes no construtor da classe. Sendo eles:\n",
    "\n",
    "- `dataset`: O conjunto de dados para o qual você deseja criar o DataLoader.\n",
    "- `batch_size`: O tamanho de cada lote de dados que irá alimentar o modelo.\n",
    "- `shuffle`: Se queremos embaralhar os dados enquanto alimentamos o modelo Se nao for especificado, o padrão é `False` Geralmente usamos `True` quando estamos treinando o modelo, mas False durante a validação e teste.\n",
    "- `num_workers`: O número de threads(processos) que queremos usar para carregar os dados em paralelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exemplo:\n",
    "Neste exemplo, vamos criar primeiramente um objeto `DataLoader` chamado `sample_dataloader` e vamos passar como argumento o conjunto de dados que queremos carregar que chamamos de `sample_dataset` e vamos especificar um batch_size de 32 itens por \"batelada\" e sem embaralhá-los.\n",
    "\n",
    "Obs: Nós também podemos passar outros argumentos para o DataLoader, como por exemplo `sampler` que é um objeto da classe `Sampler` que é responsável por amostrar os dados de uma forma específicada, além deste argumento podemos passar outros ainda mais complexos que sao específicos para cada casa de uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "sample_dataloader = DataLoader(dataset=\"sample_dataset\", batch_size=32, shuffle=False,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entendendo como o DataLoader funciona\n",
    "Instanciar ou criar um objeto DataLoader, nos retorna um objeto que é um iterador sobre o conjunto de dados ou seja um iteravél. Este iteravél é executado no conjunto de dados e retorna um lote de dados a cada iteração. Portanto, em cada iteracao, um lote itens(dados) será retornado, e estes serao os dados que alimentarao a rede neural.\n",
    "\n",
    "Mas como o DataLoader faz isso?\n",
    "\n",
    "Bom, para fazer isso o `DataLoader` utiliza alguns métodos built-in que são os métodos `__getitem__()` ou `__iter__()` dependendo de como criamos ou melhor definimos lá na classe `DataClass`. Portanto, é necessário que cada `DataClass` seja ela implementada ou as fornecidas pelo core do Pytorch, é de extrema importância cada uma das `DataClass` tenha algum destes 2 métodos implementados.\n",
    "\n",
    "No exemplo que vimos anteriormente podemos perceber algumas coisas que sao importantes de serem observadas sao:\n",
    "\n",
    "1. Nós criamos o objeto `sample_dataloader` para alimentar o modelo `sample_dataset`.\n",
    "2. `sample_dataloader` é um objeto iterador que será executado em `sample_dataset`.\n",
    "3. Em cada iteracao de `sample_dataloader` um lote de 32 itens é retornado. E entao este lote irá alimentar o modelo da rede neural.\n",
    "4. `sample_dataloader` internamente faz uso dos métodos `__getitem__()` ou `__iter__()` dependendo de como criamos ou melhor definimos lá na classe `DataClass`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando um carregador de dados (DataLoader)\n",
    "\n",
    "Normalmente criamos os carregadores de dados(DataLoader) de maneira separadas para alimentar o modelo, mas como assim separados? Bom normalmente quando trabalhamos com Deep Learning, Machine Learning e etc, nós particionamos ou quebramos o dataset em 3 partes que chamamos de `train`, `test` e `val` (treino, teste e validacao), isso serve justamente para ver o quao bom este modelo que acabou de ser treinado é, pois iremos ver a capacidade de generalização do modelo com dados que ele nunca viu, isso é muito importante para otimizar o processo de treinamento e evitar o overfitting.\n",
    "\n",
    "Logo, ao separarmos o dataset em 3 partes, normalmente eles estarao em 3 diretorios diferentes, e sendo assim, precisamos criar um carregador para cada um destas partes do dataset e portanto, o uso de diferentes carregadores de dados neste caso é necessário. Da mesma forma, embaralhar os dados pode ser útil ao treinar o modelo, mas pode não ser necessário durante os processos de validação e teste, vamos ver como poderiamos fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\"train_dataset\", batch_size = 32, shuffle = True)\n",
    "val_dataloader = DataLoader(\"val_dataset\", batch_size = 32, shuffle = False)\n",
    "test_dataloader = DataLoader(\"test_dataset\", batch_size = 32, shuffle = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unicamp-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
