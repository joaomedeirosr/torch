{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A classe Dataset do Pytorch\n",
    "\n",
    "A classe **Dataset** do Pytorch, é a classe mais básica para representar e manipular um dado dataset ou conjunto de dados. Todas as outras classes de datasets, que existe no core do Pytorch, herdam da Datasetclass. Enquanto o Pytorch também fornece muitas outras classes de conjunto de dados para manipular vários tipos de conjuntos de dados, nós podemos criar a nossa própria classe para representar e ou manipular um dado conjunto de dados específico, e para isso seja possível basta que herdamos nesta nossa classe personalizada a **Datasetclass** que é a classe priordial de datasets do Pytorch.\n",
    "\n",
    "Quando é interessante criar nossa própria classe de dataset ?\n",
    "\n",
    "É interessante, criar sua própria classe de dataset, quando os seus dados rotuládos por exemplo, tem um implementacao específica ou, possui um formato que as classes do Pytorch nao dao suporte para aquele tipo específico de dados. Ou seja, resumindo: **é interessante criar uma classe dataset personalizada quando estamos trabalhando com um modelo o um contexto de dados muito específico**.\n",
    "\n",
    "Bom, e como podemos utilizar a classe Dataset, já implementada no Pytorch?\n",
    "\n",
    "Para isso veja abaixo como pode realizar esta operacao:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criando sua própria classe Dataset\n",
    "Anteriormente comentamos que é possível criar uma classe Dataset, para lidar com um contexto específico dos dados do nosso modelo. Mas como fazer isso?\n",
    "\n",
    "Bom, para ser possível criar nossa própria classe Dataset na prática, a principal etapa é herdar a classe primordial `Dataset` do Pytorch. Feito isso, é muito importante utilizarmos ou melhor implementarmos, 2 dunder methods do Python sendo eles o `__getitem__()` e o `__len__()`. \n",
    "\n",
    "Caso, o `__getitem__` nao for implementado uma Exception, será levantada e teremos um erro. o que torna ele um dunder method obrigatório para a implementacao da classe Dataset.\n",
    "\n",
    "Adicionalmente, ao `__getitem__` é interessante utilizar o `__len__` isso se deve ao fato de que a maioria dos samplers ou os loaders de dados, utilizam deste dunder method para carregar o conjunto de dados para alimentar as arquiteturas de **Rede neural** o que torna ele um método fundamental e muito útil porém nao obrigatório.\n",
    "\n",
    "Perfeito, porém o que estes \"métodos mágicos\" retornam ou fazem?\n",
    "\n",
    "O `__getitem__` deve retornar um item do seu conjunto de dados, em um indice ou posicao. Ou seja, os dados retornados devem ser uma tupla contendo (input,label). Ou seja ele contém a matriz ou tensor de entrada, juntamente com seu respectivo rótulo, como se estivesse mapeando x em y. Já o método `__len__` retorna o número de elementos ou tamanho do dataset.\n",
    "\n",
    "Obs: Só devemos herdar a classe core Dataset do Pytorch caso o meu dataset seja baseado em mapa ou seja onde eu tenho uma entrada (x) e um rótulo (y). Ou seja, se minha classe mapeia um determinado indice(rótulo) para um tensor de entrada(item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Diretório com todas as imagens\n",
    "            transform (callable, optional): Transformações a serem aplicadas nas imagens\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None) -> None:\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Lista todos os arquivos de imagem no diretório (Se sao imagens .png, .jpg, .jpeg)\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "       \n",
    "        # Para este exemplo, vamos criar rótulos aleatórios\n",
    "        # Em um caso real, você carregaria os rótulos de um arquivo (COCO, json, csv, etc)\n",
    "        self.labels = np.random.randint(0, 10, size=len(self.image_files))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Implementar aqui a lógica para pegar cada do item do dataset no indice index.\n",
    "        \n",
    "        # Obtém o rótulo correspondente\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Aplica transformações se houver\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Implementar aqui a lógica para retornar o tamanho do dataset.\n",
    "         return len(self.image_files)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dataset = myDataset(root_dir='///', transform = None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outras classes do núcleo do Pytorch\n",
    "\n",
    "Pytorch oferece inúmeras outras classes para lidar com conjuntos de dados de vários tipos, veja\n",
    "\n",
    "| Classes de Dataset   | Particularidades |\n",
    "|------------------------------|------------|\n",
    "| `IterableDataset`            | `IterableDataset` é uma subclasse de `Dataset` usada para manipular dados vindos de um fluxo. Ao contrário de `Dataset`, não é um conjunto de dados baseado em mapa. Portanto, em vez de implementar o método `__getitem__()`, você terá que implementar o método `__iter__()`, que deve retornar um iterador que iterará sobre o conjunto de dados. Você pode herdar a classe `IterableDataset` para criar sua própria classe que itera sobre os dados. |\n",
    "| `ChainDataset`               | `ChainDataset` é uma subclasse de `IterableDataset` usada para encadear eficientemente múltiplos conjuntos de dados do tipo `IterableDataset`. Esta classe pode ser útil ao combinar/encadear `IterableDataset`s existentes de diferentes fluxos de dados. |\n",
    "| `BufferedShuffleDataset`     | `BufferedShuffleDataset` é uma subclasse de `IterableDataset` usada para embaralhar itens de um `IterableDataset`. Esta classe pode ser útil quando itens de um `IterableDataset` existente precisam ser embaralhados. |\n",
    "| `TensorDataset`              | `TensorDataset` é uma subclasse de `Dataset` usada para manipular conjuntos de dados na forma de um tensor. |\n",
    "| `ConcatDataset`              | `ConcatDataset` é uma subclasse de `Dataset` usada para concatenar vários conjuntos de dados existentes. |\n",
    "| `Subset`                     | `Subset` é uma subclasse de `Dataset` usada para criar um conjunto de dados que é um subconjunto do conjunto de dados original. Este subconjunto é criado a partir de itens nos índices fornecidos no conjunto de dados original. |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unicamp-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
