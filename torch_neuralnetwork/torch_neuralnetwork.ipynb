{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando uma rede neural no Pytorch\n",
    "\n",
    "Uma das funcionalidades mais básicas de qualquer biblioteca de Deep Learning é proporcionar para os usuários uma maneira mais simplificada de se criar redes neurais. E este é justamente o que o Pytorch faz.\n",
    "\n",
    "Vamos entao, neste capítulo, ver como podemos criar uma rede neural no Pytorch. Neste caso, vamos implementar um modelo mais simples de rede neural ou seja, vamos ver na prática como criar um modelo feedforward de rede neural (ANN) utilizando o Pytorch.\n",
    "\n",
    "Bom, o primeiro passo para criar uma rede neural no Pytorch é criar uma classe para a rede neural, e depois instânciar\n",
    "\n",
    "Porém antes disso é importante importar alguns módulos como por exemplo: \n",
    "\n",
    "```python\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "````\n",
    "\n",
    "#### Criando sua própria rede neural\n",
    "\n",
    "Vimos, em alguns módulos anteriores como criar seu próprio DataLoader e até mesmo a como criar e trabalhar com uma implementacao simples de uma rede neural. Agora vamos detalhar um pouco mais como criar sua própria ANN (rede neural artificial) do tipo feedfoward.\n",
    "\n",
    "Para criar um modelo próprio, normalmente devemos herdar da classe `nn.Module`, e como estamos trabalhando com um modelo de ANN. É necessário que facamos a implementacao do construtor da classe da minha ANN e também do método `forward()`. Algo que podemos tirar como conclusao disso é que a arquitetura do modelo será definida pela classe que criarmos, e o fluxo de como os dados sao propagados pela ANN é definido pelo método `forward()` Vamos, implementar na prática para ter um melhor entendimento do que foi exposto neste paragráfo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "    # Arquitetura de como funciona a ANN\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        # implementacao dos dados\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entao, o que temos acima é um exemplo, bem simplificado apenas mostrando o construtor e o método `forward()`. Vamos agora implementar a arquitetura da rede e termos de fato um código mais completo e coerente com o que seria a construcao de uma ANN, no Pytorch.\n",
    "\n",
    "##### Arquitetura do Modelo\n",
    "\n",
    "Como mencionado anteriormente, a arquitetura do modelo é definida no construtor da classe. E sendo assim, as camadas da rede sao adicionada como atributos ou (\"variaveis\") dentro do construtor.\n",
    "\n",
    "Para o nosso modelo em questao, vamos utilizar apenas 3 camadas densas que consistem:\n",
    "\n",
    "- dense_layer1: A primeira camada densa contendo 784 entradas e 300 saídas.\n",
    "- dense_layer2: A segunda camada densa contendo 300 entradas e 100 saídas.\n",
    "- dense_layer3: A terceira camada densa contendo 100 entradas e 10 saídas.\n",
    "\n",
    "Para fazermos isso, devemos herdar da classe `nn.Module` e herdar também seu construtor através de `super()`. E isso deverá acontecer sempre que formos criar uma nova classe para um modelo de rede neural. Esta chamada é fundamental para o que Pytorch possa inicializar corretamente a classe pai `nn.Module`, configurando o sistema de registro automático de parametros, para que tenhamos se necessário o mecanismo de autograd para o backpropagation e também o gerenciamento correto dos parametros treinaveis. Resumindo, precisamos sempre ter a estrutura:\n",
    "\n",
    "```python\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        # Modelo da rede aqui.\n",
    "```\n",
    "\n",
    "Vamos agora entao implementar de fato a arquitetura da ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        dense_layer1 = nn.Linear(784, 300)\n",
    "        dense_layer2 = nn.Linear(300, 100)\n",
    "        dense_layer3 = nn.Linear(100, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fluxo de dados através do modelo\n",
    "\n",
    "Vamos, agora implementar o método `forward()` que como vimos é reponsável por propagar os dados ao longo da ANN. Quando mencionamos propagar queremos dizer a maneira como os dados da entrada serao modificados por exemplo, quais camadas de ativacao serao utilizadas, tudo isso é definido no método `forward()`. Para este exemplo, iremos aplicar 2 funcoes de ativacao nas saídas das dense_layer1 e dense_layer2 aplicaremos `ReLU` e por fim na dense_layer3 aplicaremos `Softmax`. Opcionalmente podemos executar operacoes para modificar os dados do tensor de entrada para o formato desejado. Portanto, vamos implementar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "   x = F.relu(self.dense_layer1)\n",
    "\n",
    "   x = F.relu(self.dense_layer2)\n",
    "\n",
    "   x = F.softmax(self.dense_layer3)\n",
    "\n",
    "   return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, pronto ja temos nossa ANN implementada. devemos apenas instanciar ou inicializar a nossa classe e teremos nosso modelo de ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_model = MyNeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código completo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ANN_net(\n",
       "  (dense_layer1): Linear(in_features=784, out_features=300, bias=True)\n",
       "  (dense_layer2): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (dense_layer3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ANN_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN_net, self).__init__()\n",
    "        self.dense_layer1 = nn.Linear(784, 300)\n",
    "        self.dense_layer2 = nn.Linear(300, 100)\n",
    "        self.dense_layer3 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense_layer1)\n",
    "        x = F.relu(self.dense_layer2)\n",
    "        x = F.softmax(self.dense_layer3)\n",
    "        return x\n",
    "\n",
    "ann_model = ANN_net()\n",
    "ann_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unicamp-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
