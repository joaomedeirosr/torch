{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü•á Funcoes de reducao utilizadas no Pytorch\n",
    "\n",
    "No Pytorch as funcoes de reducao, sao utilizadas para reduzir a dimensionalidade dos tensores, agregando valores ao longo de uma ou mais dimensoes.\n",
    "\n",
    "No Pytorch, t√™m-se uma s√©rie de m√©todos, entretanto vamos nos concentrar em alguns dos mais utilizados no dia a dia ao se trabalhar com Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üîé O parametro dim (dimension)\n",
    "\n",
    "Antes de ja irmos direto para os m√©todos √© necess√°rio antes abordar um conceito importantissimo ao se trabalhar com funcoes de reducao no Pytorch que √© o **dimension**.\n",
    "\n",
    "Logo, ao trabalhar com m√©todos de reducao no Pytorch, o parametro `dim=<value>`, serve para auxiliar o usu√°rio pois ao utiliz√°-lo, √© necess√°rio informar em **qual ou para qual dimensao o m√©todo deve ser aplicado**.\n",
    "\n",
    "O par√¢metro `dim` representa literalmente a dimensao e portanto, ao utilizarmos precisamos **informar passando um n√∫mero inteiro que representa a dimensao**. \n",
    "\n",
    "Um conceito muito importante, em relacao ao `dim` √© que os valores devem ser **n√∫meros inteiros**, que **sempre iniciam em 0** e esses valores, podem aumentar sequencialmente, ao passo que o Tensor aumenta a sua ordem. \n",
    "\n",
    "Outro conceito importante √© que sempre o maior valor de `dim`, sempre ser√° relativo as colunas, e os demais valores serao responsav√©is pelas linhas, independente da ordem do tensor que se estiver trabalhando.\n",
    "\n",
    "Sendo assim, as dimensoes em vetores de ordem 2, sao n√∫meradas por:\n",
    "\n",
    "- **0 = Representa as Linhas** \n",
    "- **1 = Representa as Colunas**\n",
    "\n",
    "Para facilitar um pouco o entendimento, pense que quando voce delimita `dim=0` voce est√° aplicando o m√©todo de reducao no eixo Y. J√° quando voce delimita `dim=1` voce est√° aplicando o m√©todo no eixo X.\n",
    "\n",
    "Vamos entao ver como trabalhar com um tensores de ordem 2 (matriz) para verificar como que esses m√©todos de agregacao funcionam nestes tensores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. torch.sum():\n",
    "O m√©todo `torch.sum()`, basicamente faz o que o nome exprime, calcula a soma de todos os elementos de um Tensor ao longo de uma dimensao que √© passada por argumento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int16)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "v = torch.ones(10,dtype=torch.int16)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que ao utilizarmos logo abaixo o m√©todo `torch.sum()` e informando a ele o tensor `v` ele acessa este tensor de ordem 1, que foi gerado atrav√©s de um m√©todo de inicializacao neste caso o `torch.ones()` e realiza uma soma neste tensor, ou seja faz uma agregacao o transformando em um escalar de valor 10. Ou seja, realizou a agregacao e reduziu a dimensao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos utilizar a mesma ideia por√©m utilizando um tensor de ordem superior neste caso, um tensor de ordem 2 (matriz) e veremos que a mesma ideia feita para o tensor de ordem 1 tamb√©m √© v√°lida para tensores de ordem superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]], dtype=torch.int16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrice_m = torch.ones(2,3,dtype=torch.int16)\n",
    "matrice_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que novamente, o que o m√©todo `torch.sum` realizou foi literalmente somar cada elemento tanto das linhas quanto das colunas 1 a 1 e reduziu a dimensionalidade do tensor para um tensor de ordem 0, ou seja, retornou um escalar valendo 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_sum = torch.sum(matrice_m)\n",
    "tensor_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3830, 0.9119, 0.8695],\n",
       "        [0.2018, 0.0105, 0.6678]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_matrice = torch.rand(2,3)\n",
    "random_matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que aqui neste caso, o m√©todo `torch.sum()`, realizou a soma de cada elemento da primeira e da segunda linha do tensor random_matrice, pois especificamos o par√¢metro `dim` tire a prova real calculando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5848, 0.9224, 1.5372])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(random_matrice,dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que ao somar todos os valores de cada elemento de cada linha, obtivemos o valor de **1.3356**, pois questoes de precisao nos algarismos e o tamanho do tipo de dados o √∫ltimo digito da casa decimal foi arredondada. Por√©m o valor de fato esta identico ao valor encontrado quando aplicamos o m√©todo `torch.sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3356"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0307 + 0.5181 + 0.7868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos, replicar a ideia por√©m agora, para a dimensao 0. Veja que agora, o m√©todo somou apenas os valores que estavam nas colunas **dim = 0**, de maneira an√°loga ao que fizemos para a dimensao 1, vamos tirar a \"prova real\" para verificar a acur√°cia.\n",
    "\n",
    "Portanto, temos exatamente os valores encontrados ao utilizar o parametro torch.sum por√©m agora apenas em uma diferenca diferente o que podemos concluir que o comando est√° correto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1644, 0.8801])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(random_matrice,dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0942, 1.1343999999999999, 1.7656)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.0307 + 0.0635) , (0.5181 + 0.6163) , (0.7868 + 0.9788)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos aplicar estes conceitos para Tensores de ordem superior ou ordem 3 e ver se as funcoes de agregacao, seguem os conceitos vistos anteriormente at√© aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comecarmos, a trabalhar com m√©todos de agregacao em Tensores de ordem superior gostaria de lembrar um conceito visto em estudos anteriores\n",
    "\n",
    "**O que sao tensores de ordem superior por exemplo um tensor de ordem 3 ?**\n",
    "\n",
    "Vimos, que um tensor de ordem 3 em termos pr√°ticos √© um vetor que carrega em si matrizes guarde este conceito pois ele ser√° importante!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3254, 0.0531, 0.1916],\n",
       "         [0.3600, 0.9394, 0.0500]],\n",
       "\n",
       "        [[0.5365, 0.5318, 0.1528],\n",
       "         [0.3453, 0.2539, 0.2998]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d = torch.rand(2,2,3)\n",
    "\n",
    "tensor3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5701, 1.3494],\n",
       "        [1.2211, 0.8990]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(tensor3d, dim = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos, somar manualmente para verificar se de fato a operacao est√° correta e visualizar que ele est√° somando as colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6363, 0.9390999999999999, 0.7236, 1.2471999999999999)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9441 + 0.8208 + 0.8714) , (0.3552 + 0.5126 + 0.0713) , (0.1126 + 0.4456 + 0.1654) , (0.276 + 0.4406 + 0.5306)\n",
    "\n",
    "# Logo, vimos que sim est√° sendo somado corretamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos explorar a `dim = 0` que ir√° realizar a operacao na dimensao \"3\". Pois como tinhamos abordado um tensor de ordem superior, como neste caso de ordem 3, em termos pr√°ticos √© um vetor que carrega matrizes e portanto, neste caso o que ocorrer√° √© uma operacao de soma entre as matrizes vamos ver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3254, 0.0531, 0.1916],\n",
       "         [0.3600, 0.9394, 0.0500]],\n",
       "\n",
       "        [[0.5365, 0.5318, 0.1528],\n",
       "         [0.3453, 0.2539, 0.2998]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8619, 0.5849, 0.3444],\n",
       "        [0.7054, 1.1933, 0.3497]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.sum(tensor3d, dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, vamos realizar os calculos para ver se de fato a operacao foi aplicada na dimensao correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0567, 1.2664, 1.0368)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9441 + 0.1126) , (0.8208 + 0.4456) , (0.8714 + 0.1654)\n",
    "\n",
    "# Veja que sim, a operacao foi aplicada na dimensao correta, realizando a soma de elemento por elemento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. torch.mean():\n",
    "\n",
    "O m√©todo `torch.mean()`, basicamente faz o que o nome exprime, calcula a m√©dia de todos os elementos de um Tensor ao longo de uma dimensao especificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2145, 0.9650, 0.5482, 0.3012, 0.4591, 0.2867, 0.2246])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_vector = torch.rand(7)\n",
    "\n",
    "another_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4285)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(another_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos entao testar de maneira \"brute force\" para ver se de fato a operacao esta correta:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4112571428571429"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8636 + 0.0433 + 0.0769 + 0.6007 + 0.6226 + 0.4043 + 0.2674) / 7\n",
    "\n",
    "#Portanto, de fato est√° correto a operacao utilizando o m√©todo mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos realizar a aplicacao do `torch.mean()`, por√©m para tensores de ordem 2. E vamos utilizar o parametro `dim`, que vimos anteriormente para que o m√©todo seja aplicado para a dimensao determinada como tamb√©m j√° foi visto anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2118, 0.7054, 0.9934],\n",
       "        [0.8409, 0.3987, 0.9036]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_matrice = torch.rand(2,3)\n",
    "another_matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6369, 0.7144])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(another_matrice, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7376999999999999 0.5393666666666667\n"
     ]
    }
   ],
   "source": [
    "# Testando:\n",
    "\n",
    "# o dim = 1, como visto representa as colunas, portanto:\n",
    "\n",
    "# C√°lculo do primeiro elemento\n",
    "a11 = (0.7593 + 0.8597 + 0.5941) / 3\n",
    "\n",
    "# C√°lculo do segundo elemento\n",
    "a12 = (0.8635 + 0.3544 + 0.4002) / 3\n",
    "\n",
    "print(a11,a12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, veja que os mesmos conceitos como por exemplo: uso do `dim` que utilizamos para o `torch.sum()`, tamb√©m funcionam para os demais m√©todos como por exemplo neste caso o `torch.mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2118, 0.7054, 0.9934],\n",
       "        [0.8409, 0.3987, 0.9036]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5264, 0.5521, 0.9485])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(another_matrice, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8114 0.60705 0.49715\n"
     ]
    }
   ],
   "source": [
    "# Testando: \n",
    "# dim = 0 , representa as colunas:\n",
    "\n",
    "a11 = (0.7593 + 0.8635) / 2\n",
    "a12 = (0.8597 + 0.3544) / 2\n",
    "a13 = (0.5941 + 0.4002) / 2\n",
    "\n",
    "print(a11,a12,a13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0260, 0.6126, 0.7707],\n",
       "         [0.7533, 0.9096, 0.1928]],\n",
       "\n",
       "        [[0.7389, 0.7655, 0.2077],\n",
       "         [0.2560, 0.9505, 0.2074]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_tensor = torch.rand(2,2,3)\n",
    "another_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3824, 0.6890, 0.4892],\n",
       "        [0.5047, 0.9300, 0.2001]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(another_tensor, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3896, 0.7611, 0.4817],\n",
       "        [0.4975, 0.8580, 0.2075]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(another_tensor, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4697, 0.6186],\n",
       "        [0.5707, 0.4713]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(another_tensor, dim = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. torch.max():\n",
    "\n",
    "O m√©todo `torch.max()`, nos mostra qual √© o maior valor presente dentro de um tensor. Retornando isso, atrav√©s do seu valor ou da sua posicao(index). Al√©m disso, como ja visto nos m√©todos anteriores como `torch.sum()` e `torch.mean()`, aqui com o `torch.max()` tamb√©m podemos especificar em qual dimensao, queremos que o m√©todo seja aplicado.\n",
    "\n",
    "Um ponto importante a ser salientado √© que quando estamos trabalhando com os m√©todos de reducao, eles verificam elemento por elemento aplicando suas operacoes, entao por exemplo no m√©todo `torch.max()` ele ir√° sair comparando elemento a elemento para verificar qual deles √© maior. E isso vale tamb√©m para quando passamos parametros adicionais como por exemplo `torch.max(dim='0 ou 1')` Ou seja, quando delimitamos a dimensao o que ir√° acontecer √© que o m√©todo ir√° aplicar sua l√≥gica neste caso \"filtrar\" pelo elemento de maior valor e para isso ele ir√° comparar elemento por elemento na dimensao informada, se `dim=0` ele ir√° comparar elemento por elemento presente nas linhas e retornar√° o valor e a respectiva posicao dos maiores elementos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicando torch.max() em tensores de ordem 2 ou matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7485, 0.3832, 0.5739],\n",
       "        [0.8960, 0.9712, 0.3480]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix4 = torch.rand(2,3)\n",
    "\n",
    "matrix4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que aqui nao informamos a dimensao, entao de maneira geral o m√©todo `torch.max` procurou pelo maior valor entre todos os valores do Tensor e nos retornou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9712)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(matrix4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.8960, 0.9712, 0.5739]),\n",
       "indices=tensor([1, 1, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(matrix4, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8960, 0.9712, 0.5739]), tensor([1, 1, 0]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index, values = torch.max(matrix4, dim = 0)\n",
    "\n",
    "index, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos, ver como isso funciona na `dim=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7485, 0.9712]), tensor([0, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index, values = torch.max(matrix4, dim = 1)\n",
    "\n",
    "index, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicando o torch.max() em tensores de ordem 3 ou superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1781, 0.4586, 0.5749],\n",
       "         [0.3675, 0.2402, 0.2650]],\n",
       "\n",
       "        [[0.6796, 0.1474, 0.3033],\n",
       "         [0.5824, 0.4717, 0.6007]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2,2,3)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos at√© entao que nos tensores de ordem menor que 3, o parametro `dim` pode ser `dim=0` e `dim=1`. Isso informa para o **Pytorch** que neste caso √© para aplicar o m√©todo de reducao em questao na dimensao especificada onde `dim = 0`, aplica o m√©todo na dimensao das linhas e `dim = 1`, aplica o m√©todo na dimensao na dimensao das colunas. Por√©m, agora ao trabalharmos com tensores de ordem 3 ou superior, estamos de fato tendo que lidar com um Tensor propriamente dito, ou para simplificar estamos lidando com um \"vetor de matrizes\". E sendo assim, agora nos tensores de ordem 3, estamos lidando com uma dimensao a mais, com isso nosso parametro `dim` tamb√©m \"ganha\" uma dimensao a mais e temos o seguinte:\n",
    "\n",
    "- `dim = 0`: Aplica o m√©todo na dimensao das **matrizes**\n",
    "- `dim = 1`: Aplica o m√©todo na dimensao das **linhas**\n",
    "- `dim = 2`: Aplica o m√©todo na dimensao das **colunas**\n",
    "  \n",
    "Para que isso fique um pouco mais claro de entender, √© que nos Tensores de ordem maior que 3, o valor **0** est√° associado com a primeira dimensao que neste caso sao as \"matrizes\", o valor **1** est√° ligado com as linhas das matrizes em questao e o valor **2** fica ligado com as colunas e portanto, temos est√° pequena diferenca e podemos fazer inclusive uma analogia com o eixo de coordenadas x,y,z , pois √© como se tivessemos controlando o eixo:\n",
    "$$x = 0; y = 1;  z = 2; $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testando a dimensao `dim = 2` que controla as colunas em tensores de ordem superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "values , index = torch.max(t, dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1781, 0.4586, 0.5749],\n",
       "         [0.3675, 0.2402, 0.2650]],\n",
       "\n",
       "        [[0.6796, 0.1474, 0.3033],\n",
       "         [0.5824, 0.4717, 0.6007]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5749, 0.3675],\n",
       "        [0.6796, 0.6007]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testando a dimensao `dim = 1` que controla as linhas em tensores de ordem superior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entao veja que aqui ele est√° comparando elemento por elemento de cada linha e vendo qual deles √© maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1781, 0.4586, 0.5749],\n",
       "         [0.3675, 0.2402, 0.2650]],\n",
       "\n",
       "        [[0.6796, 0.1474, 0.3033],\n",
       "         [0.5824, 0.4717, 0.6007]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,index = torch.max(t, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3675, 0.4586, 0.5749],\n",
       "        [0.6796, 0.4717, 0.6007]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testando a dimensao `dim = 0` que controla as matrizes em tensores de ordem superior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J√° aqui veja que ele est√° comparando elemento por elemento de cada uma das matrizes e vendo qual √© o maior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1781, 0.4586, 0.5749],\n",
       "         [0.3675, 0.2402, 0.2650]],\n",
       "\n",
       "        [[0.6796, 0.1474, 0.3033],\n",
       "         [0.5824, 0.4717, 0.6007]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,index = torch.max(t, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6796, 0.4586, 0.5749],\n",
       "        [0.5824, 0.4717, 0.6007]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. torch.min():\n",
    "\n",
    "O `torch.min()` tem o pr√≠ncipio de funcinamento exatamente igual ao `torch.max()` visto anteriormente, a √∫nica diferenca √© que o `torch.min()` ir√° retornar o menor valor do Tensor ou ir√° aplicar o m√©todo e retornar√° os menores valores de um tensor em uma dada dimensao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0557, 0.1917, 0.2341],\n",
       "         [0.6657, 0.9000, 0.5472]],\n",
       "\n",
       "        [[0.1237, 0.9808, 0.5441],\n",
       "         [0.7009, 0.8810, 0.6214]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.rand(2,2,3)\n",
    "\n",
    "t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba, que se eu nao informar nenhuma dimensao ou seja nao informar o parametro `dim` o m√©todo `torch.min()` ir√° retornar o menor valor do Tensor entre todos independente das dimensoes do Tensor, isso vale para qualquer um dos m√©todos de reducao como por exemplo: `torch.sum()`, `torch.max()` e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0557)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que no momento em que uma dimensao √© informada, ele ir√° realizar e procurar o menor valor daquela dimensao exatamente igual vimos, quando trabalhamos com `torch.max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, index = torch.min(t2, dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0557, 0.5472],\n",
       "        [0.1237, 0.6214]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, index = torch.max(t2, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6657, 0.9000, 0.5472],\n",
       "         [0.7009, 0.9808, 0.6214]]),\n",
       " tensor([[1, 1, 1],\n",
       "         [1, 0, 1]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, index = torch.min(t2, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0557, 0.1917, 0.2341],\n",
       "         [0.6657, 0.8810, 0.5472]]),\n",
       " tensor([[0, 0, 0],\n",
       "         [0, 1, 0]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. torch.argmax():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `torch.argmax()` tem um funcionamento e l√≥gica muito semelhante, ao funcionamento do `torch.max()`, por√©m a diferenca existente entre eles √© que o `torch.max()` retorna os maiores valores jutamente com os indices ou melhor as posicoes onde est√° localizado estes maiores valores e j√° no `torch.argmax()` o retorno que temos como resultado √© apenas as posicoes de onde estao os maiores valores neste Tensor. Assim como no `torch.max()`, podemos realizar a busca por este maior valor atrav√©s de uma dimensao especifica, como ja vimos passando o parametro adicional `dim = 0` , `dim = 1` e `dim = 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9311, 0.6232, 0.2368],\n",
       "         [0.4186, 0.9345, 0.9238]],\n",
       "\n",
       "        [[0.7209, 0.4918, 0.0780],\n",
       "         [0.7135, 0.0741, 0.5789]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.rand(2,2,3)\n",
    "\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(t3, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1],\n",
       "        [0, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(t3, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(t3, dim = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. torch.argmin():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `torch.argmin()` tamb√©m √© exatamente o mesmo m√©todo, que o `torch.argmax()` por√©m com a diferenca de que a l√≥gica aqui √© que teremos como retorno a posicao(index) do menor valor dentro do vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9311, 0.6232, 0.2368],\n",
       "         [0.4186, 0.9345, 0.9238]],\n",
       "\n",
       "        [[0.7209, 0.4918, 0.0780],\n",
       "         [0.7135, 0.0741, 0.5789]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [0, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(t3, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 1, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(t3, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0],\n",
       "        [2, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(t3, dim = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unicamp-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
